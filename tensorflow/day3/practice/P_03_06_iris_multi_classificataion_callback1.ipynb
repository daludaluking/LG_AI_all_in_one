{"nbformat":4,"nbformat_minor":2,"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python3","display_name":"Python 3.8.10 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"P_03_06_iris_multi_classificataion_callback1.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"14c878ca9e09cb855c5aba830c5d56400199f035e888de3a1c3895cb2a489872"}},"cells":[{"cell_type":"code","execution_count":1,"source":["import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import pandas as pd\n","import math\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Currently, memory growth needs to be the same across GPUs\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","  except RuntimeError as e:\n","    # Memory growth must be set before GPUs have been initialized\n","    print(e)"],"outputs":[{"output_type":"stream","name":"stdout","text":["1 Physical GPUs, 1 Logical GPUs\n"]}],"metadata":{"id":"L66KdtwEyh8B"}},{"cell_type":"code","execution_count":2,"source":["\n","def step_decay(epoch):\n","\tinitial_lrate = 0.001\n","\tdrop = 0.98\n","\tepochs_drop = 50.0\n","\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n","\treturn lrate\n","\n"],"outputs":[],"metadata":{"id":"y6YX2XF9ymbs","executionInfo":{"status":"ok","timestamp":1629215184517,"user_tz":-540,"elapsed":13,"user":{"displayName":"김현우","photoUrl":"","userId":"06560543018646300359"}}}},{"cell_type":"code","execution_count":4,"source":["\n","# 데이터 입력\n","df = pd.read_csv('../dataset/iris.csv', names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n","\n","# 데이터 분류\n","dataset=df.copy()\n","\n","# 데이터 분류\n","Y_obj=dataset.pop(\"species\")\n","X=dataset.copy()\n","\n","# 문자열을 숫자로 변환\n","Y_encoded=pd.get_dummies(Y_obj)\n"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"wFPOUazByrbD","executionInfo":{"status":"error","timestamp":1629215185478,"user_tz":-540,"elapsed":17,"user":{"displayName":"김현우","photoUrl":"","userId":"06560543018646300359"}},"outputId":"08a2b03f-4c10-4368-ca71-ad0655897689"}},{"cell_type":"code","execution_count":5,"source":["\n","# 전체 데이터에서 학습 데이터와 테스트 데이터(0.1)로 구분\n","X_train1, X_test, Y_train1, Y_test = train_test_split(X, Y_encoded, test_size=0.3,shuffle=True, stratify=Y_encoded)  ## shuffle=True로 하면 데이터를 섞어서 나눔\n","## 학습 셋에서 학습과 검증 데이터(0.2)로 구분\n","X_train, X_valid, Y_train, Y_valid = train_test_split(X_train1, Y_train1, test_size=0.2, shuffle=True, stratify=Y_train1)  ## shuffle=True로 하면 데이터를 섞어서 나눔\n","\n"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"x-WgfkLUytYZ","executionInfo":{"status":"error","timestamp":1629215190808,"user_tz":-540,"elapsed":498,"user":{"displayName":"김현우","photoUrl":"","userId":"06560543018646300359"}},"outputId":"43629bfe-0d40-4cfe-af5e-2c1a4df4a959"}},{"cell_type":"code","execution_count":6,"source":["\n","# 모델의 설정\n","activation=tf.keras.activations.sigmoid\n","input_Layer = tf.keras.layers.Input(shape=(4,))\n","x = tf.keras.layers.Dense(16, activation=activation,)(input_Layer)\n","x = tf.keras.layers.Dense(12, activation=activation)(x)\n","Out_Layer= tf.keras.layers.Dense(3, activation='softmax')(x)\n","model = tf.keras.models.Model(inputs=[input_Layer], outputs=[Out_Layer])\n","model.summary()\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 4)]               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 16)                80        \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 12)                204       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 39        \n","=================================================================\n","Total params: 323\n","Trainable params: 323\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"ZKunglrYyurS","executionInfo":{"status":"error","timestamp":1629215196018,"user_tz":-540,"elapsed":433,"user":{"displayName":"김현우","photoUrl":"","userId":"06560543018646300359"}},"outputId":"cec10eaa-4bfb-47b6-b9c0-54eb583acdc2"}},{"cell_type":"code","execution_count":5,"source":["\n","# 모델 컴파일\n","model.compile(loss=tf.keras.losses.categorical_crossentropy,\n","             optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n","             metrics=[tf.keras.metrics.categorical_accuracy])\n","\n","modelpath=\"./best_model/{epoch:02d}-{val_loss:.4f}.h5\"\n","clabacks_list =[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=100),\n","                tf.keras.callbacks.ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True),\n","                tf.keras.callbacks.LearningRateScheduler(step_decay, verbose=1)]\n","\n","## model fit은 histoy를 반환한다. 훈련중의 발생하는 모든 정보를 담고 있는 딕셔너리.\n","result=model.fit(X_train, Y_train, epochs=50, batch_size=50, validation_data=(X_valid,Y_valid),callbacks=clabacks_list) # validation_data=(X_valid,Y_valid)을 추가하여 학습시 검증을 해줌.\n","## histoy는 딕셔너리이므로 keys()를 통해 출력의 key(카테고리)를 확인하여 무엇을 받고 있는지 확인.\n","print(result.history.keys())\n"],"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-4328513a315c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 모델 컴파일\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.compile(loss=tf.keras.losses.categorical_crossentropy,\n\u001b[0m\u001b[1;32m      4\u001b[0m              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              metrics=[tf.keras.metrics.categorical_accuracy])\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"IMwBErvyyv-a","executionInfo":{"status":"error","timestamp":1629215222952,"user_tz":-540,"elapsed":415,"user":{"displayName":"김현우","photoUrl":"","userId":"06560543018646300359"}},"outputId":"01e860c7-d2ea-4105-fea4-614a0b100b6f"}},{"cell_type":"code","execution_count":null,"source":["\n","### result에서 loss와 val_loss의 key를 가지는 값들만 추출\n","loss = result.history['loss']\n","val_loss = result.history['val_loss']\n","### loss와 val_loss를 그래프화\n","epochs = range(1, len(loss) + 1)\n","plt.subplot(211)  ## 2x1 개의 그래프 중에 1번째\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","### history에서 binary_accuracy와 val_binary_accuracy key를 가지는 값들만 추출\n","acc = result.history['categorical_accuracy']\n","val_acc = result.history['val_categorical_accuracy']\n","\n","### binary_accuracy와 val_binary_accuracy key를 그래프화\n","plt.subplot(212)  ## 2x1 개의 그래프 중에 2번째\n","plt.plot(epochs, acc, 'ro', label='Training acc')\n","plt.plot(epochs, val_acc, 'r', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","\n","# model.evalueate를 통해 테스트 데이터로 정확도 확인하기.\n","## model.evaluate(X_test, Y_test)의 리턴값은 [loss, binary_acuuracy ]  -> 위 model.compile에서 metrics=[ keras.metrics.binary_accuracy]옵션을 주어서 binary acuuracy 출력됨.\n","print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n","\n","## 그래프 띄우기\n","plt.show()"],"outputs":[],"metadata":{"id":"RDmNu122y2jk"}}]}