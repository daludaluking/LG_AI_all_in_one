{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "tf.random.set_seed(777)\n",
    "# 데이터 입력\n",
    "df = pd.read_csv('../dataset/sonar.csv', header=None)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,0:60].astype(float)\n",
    "Y_obj = dataset[:,60]\n",
    "\n",
    "# 문자열 변환\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "\n",
    "# 학습 셋과 테스트 셋의 구분\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3,shuffle=True)\n",
    "\n",
    "# 오리지날 모델 설정\n",
    "## 모델 설계하기.\n",
    "activation=tf.keras.activations.relu\n",
    "ori_input_Layer = tf.keras.layers.Input(shape=(60,))\n",
    "ori_x = tf.keras.layers.Dense(1000, activation=activation)(ori_input_Layer)\n",
    "ori_x= tf.keras.layers.Dense(1000, activation=activation)(ori_x)\n",
    "ori_x= tf.keras.layers.Dense(1000, activation=activation)(ori_x)\n",
    "ori_x= tf.keras.layers.Dense(700, activation=activation)(ori_x)\n",
    "ori_x= tf.keras.layers.Dense(700, activation=activation)(ori_x)\n",
    "ori_x= tf.keras.layers.Dense(500, activation=activation)(ori_x)\n",
    "ori_x= tf.keras.layers.Dense(500, activation=activation)(ori_x)\n",
    "ori_x= tf.keras.layers.Dense(500, activation=activation)(ori_x)\n",
    "ori_Out_Layer= tf.keras.layers.Dense(1, activation='sigmoid')(ori_x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[ori_input_Layer], outputs=[ori_Out_Layer])\n",
    "model.summary()\n",
    "\n",
    "# 모델 컴파일\n",
    "loss=tf.keras.losses.binary_crossentropy\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "metrics=tf.keras.metrics.binary_crossentropy\n",
    "model.compile(loss=loss,\n",
    "             optimizer=optimizer,\n",
    "             metrics=[metrics])\n",
    "\n",
    "\n",
    "############  경량화 모델\n",
    "## 모델 설계하기.\n",
    "small_input_Layer = tf.keras.layers.Input(shape=(60,))\n",
    "small_x = tf.keras.layers.Dense(300, activation=activation)(small_input_Layer)\n",
    "small_x= tf.keras.layers.Dense(100, activation=activation)(small_x)\n",
    "small_x= tf.keras.layers.Dense(50, activation=activation)(small_x)\n",
    "small_Out_Layer= tf.keras.layers.Dense(1, activation='sigmoid')(small_x)\n",
    "\n",
    "smaller_model = tf.keras.Model(inputs=[small_input_Layer], outputs=[small_Out_Layer])\n",
    "smaller_model.summary()\n",
    "\n",
    "# 모델 컴파일\n",
    "loss=tf.keras.losses.binary_crossentropy\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "metrics=tf.keras.metrics.binary_crossentropy\n",
    "smaller_model.compile(loss=loss,\n",
    "             optimizer=optimizer,\n",
    "             metrics=[metrics])\n",
    "\n",
    "##############\n",
    "\n",
    "####  regularizers 한 모델\n",
    "regularizers_input_Layer = tf.keras.layers.Input(shape=(60,))\n",
    "regularizers_x = tf.keras.layers.Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(regularizers_input_Layer)\n",
    "regularizers_x = tf.keras.layers.Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(regularizers_x)\n",
    "regularizers_x = tf.keras.layers.Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(regularizers_x)\n",
    "regularizers_x= tf.keras.layers.Dense(700,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(regularizers_x)\n",
    "regularizers_x= tf.keras.layers.Dense(700,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(regularizers_x)\n",
    "regularizers_x= tf.keras.layers.Dense(500,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(regularizers_x)\n",
    "regularizers_x= tf.keras.layers.Dense(500,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(regularizers_x)\n",
    "regularizers_x= tf.keras.layers.Dense(500,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(regularizers_x)\n",
    "regularizers_Out_Layer= tf.keras.layers.Dense(1, activation='sigmoid')(regularizers_x)\n",
    "\n",
    "regularizers_model = tf.keras.Model(inputs=[regularizers_input_Layer], outputs=[regularizers_Out_Layer])\n",
    "regularizers_model.summary()\n",
    "\n",
    "# 모델 컴파일\n",
    "loss=tf.keras.losses.binary_crossentropy\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "metrics=tf.keras.metrics.binary_crossentropy\n",
    "regularizers_model.compile(loss=loss,\n",
    "             optimizer=optimizer,\n",
    "             metrics=[metrics])\n",
    "\n",
    "####  dropout 한 모델\n",
    "dropout_input_Layer = tf.keras.layers.Input(shape=(60,))\n",
    "dropout_x = tf.keras.layers.Dense(1000, activation='relu')(dropout_input_Layer)\n",
    "dropout_x=tf.keras.layers.Dropout(0.5)(dropout_x)\n",
    "dropout_x = tf.keras.layers.Dense(1000, activation='relu')(dropout_x)\n",
    "dropout_x=tf.keras.layers.Dropout(0.5)(dropout_x)\n",
    "dropout_x = tf.keras.layers.Dense(1000, activation='relu')(dropout_x)\n",
    "dropout_x=tf.keras.layers.Dropout(0.5)(dropout_x)\n",
    "dropout_x= tf.keras.layers.Dense(700,activation='relu')(dropout_x)\n",
    "dropout_x=tf.keras.layers.Dropout(0.5)(dropout_x)\n",
    "dropout_x= tf.keras.layers.Dense(700,activation='relu')(dropout_x)\n",
    "dropout_x=tf.keras.layers.Dropout(0.5)(dropout_x)\n",
    "dropout_x= tf.keras.layers.Dense(500,activation='relu')(dropout_x)\n",
    "dropout_x=tf.keras.layers.Dropout(0.5)(dropout_x)\n",
    "dropout_x= tf.keras.layers.Dense(500,activation='relu')(dropout_x)\n",
    "dropout_x=tf.keras.layers.Dropout(0.5)(dropout_x)\n",
    "dropout_x= tf.keras.layers.Dense(500,activation='relu')(dropout_x)\n",
    "dropout_x=tf.keras.layers.Dropout(0.5)(dropout_x)\n",
    "dropout_Out_Layer= tf.keras.layers.Dense(1, activation='sigmoid')(dropout_x)\n",
    "\n",
    "dropout_model = tf.keras.Model(inputs=[dropout_input_Layer], outputs=[dropout_Out_Layer])\n",
    "dropout_model.summary()\n",
    "\n",
    "# 모델 컴파일\n",
    "loss=tf.keras.losses.binary_crossentropy\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "metrics=tf.keras.metrics.binary_crossentropy\n",
    "dropout_model.compile(loss=loss,\n",
    "             optimizer=optimizer,\n",
    "             metrics=[metrics])\n",
    "\n",
    "####  batchnormalization 한 모델\n",
    "batchnormal_input_Layer = tf.keras.layers.Input(shape=(60,))\n",
    "batchnormal_x = tf.keras.layers.Dense(1000, activation=None)(batchnormal_input_Layer)\n",
    "batchnormal_x = tf.keras.layers.Dense(1000, activation=None)(batchnormal_x)\n",
    "# batchnormal_x = tf.keras.layers.BatchNormalization()(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.Activation('relu')(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.Dense(1000, activation=None)(batchnormal_x)\n",
    "# batchnormal_x = tf.keras.layers.BatchNormalization()(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.Activation('relu')(batchnormal_x)\n",
    "batchnormal_x= tf.keras.layers.Dense(700,activation=None)(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.BatchNormalization()(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.Activation('relu')(batchnormal_x)\n",
    "batchnormal_x= tf.keras.layers.Dense(700,activation=None)(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.BatchNormalization()(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.Activation('relu')(batchnormal_x)\n",
    "batchnormal_x= tf.keras.layers.Dense(500,activation=None)(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.BatchNormalization()(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.Activation('relu')(batchnormal_x)\n",
    "batchnormal_x= tf.keras.layers.Dense(500,activation=None)(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.BatchNormalization()(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.Activation('relu')(batchnormal_x)\n",
    "batchnormal_x= tf.keras.layers.Dense(500,activation=None)(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.BatchNormalization()(batchnormal_x)\n",
    "batchnormal_x = tf.keras.layers.Activation('relu')(batchnormal_x)\n",
    "batchnormal_Out_Layer= tf.keras.layers.Dense(1, activation='sigmoid')(batchnormal_x)\n",
    "\n",
    "batchnormal_model = tf.keras.Model(inputs=[batchnormal_input_Layer], outputs=[batchnormal_Out_Layer])\n",
    "batchnormal_model.summary()\n",
    "\n",
    "# 모델 컴파일\n",
    "\n",
    "# 모델 컴파일\n",
    "loss=tf.keras.losses.binary_crossentropy\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "metrics=tf.keras.metrics.binary_crossentropy\n",
    "batchnormal_model.compile(loss=loss,\n",
    "             optimizer=optimizer,\n",
    "             metrics=[metrics])\n",
    "\n",
    "# 모델 실행\n",
    "model_hist=model.fit(X_train, Y_train, validation_split=0.2, epochs=500, batch_size=100)\n",
    "smaller_model_hist=smaller_model.fit(X_train, Y_train,validation_split=0.2,epochs=500, batch_size=100)\n",
    "regularizers_model_hist=regularizers_model.fit(X_train, Y_train,validation_split=0.2,epochs=500, batch_size=100)\n",
    "dropout_model_hist=dropout_model.fit(X_train, Y_train,validation_split=0.2,epochs=500, batch_size=100)\n",
    "batchnormal_model_hist=batchnormal_model.fit(X_train, Y_train,validation_split=0.2,epochs=500, batch_size=100)\n",
    "\n",
    "fig, ax = plt.subplots( 5, 1,figsize=(5,20))\n",
    "\n",
    "epochs = range(1, 501)\n",
    "original_val_loss = model_hist.history['val_loss']\n",
    "original_loss = model_hist.history['loss']\n",
    "ax[0].plot(epochs, original_val_loss, 'b+', label='val_loss')\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "ax[0].plot(epochs, original_loss, 'ro', label='loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('orig loss')\n",
    "\n",
    "epochs = range(1, 501)\n",
    "smaller_model_val_loss = smaller_model_hist.history['val_loss']\n",
    "smaller_model_loss = smaller_model_hist.history['loss']\n",
    "ax[1].plot(epochs, smaller_model_val_loss, 'b+', label='val_loss')\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "ax[1].plot(epochs, smaller_model_loss, 'ro', label='loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('smaller loss')\n",
    "\n",
    "\n",
    "epochs = range(1, 501)\n",
    "dropout_model_val_loss = dropout_model_hist.history['val_loss']\n",
    "dropout_model_loss = dropout_model_hist.history['loss']\n",
    "ax[2].plot(epochs, dropout_model_val_loss, 'b+', label='val_loss')\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "ax[2].plot(epochs, dropout_model_loss, 'ro', label='loss')\n",
    "ax[2].set_xlabel('Epochs')\n",
    "ax[2].set_ylabel('dropout loss')\n",
    "\n",
    "epochs = range(1, 501)\n",
    "regularizers_model_val_loss = regularizers_model_hist.history['val_loss']\n",
    "regularizers_model_loss = regularizers_model_hist.history['loss']\n",
    "ax[3].plot(epochs, regularizers_model_val_loss, 'b+', label='val_loss')\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "ax[3].plot(epochs, regularizers_model_loss, 'ro', label='loss')\n",
    "ax[3].set_xlabel('Epochs')\n",
    "ax[3].set_ylabel('regularizers loss')\n",
    "\n",
    "epochs = range(1, 501)\n",
    "batchnormal_model_val_loss = batchnormal_model_hist.history['val_loss']\n",
    "batchnormal_model_loss = batchnormal_model_hist.history['loss']\n",
    "ax[4].plot(epochs, batchnormal_model_val_loss, 'b+', label='val_loss')\n",
    "# ‘bo’는 파란색 점을 의미합니다\n",
    "ax[4].plot(epochs, batchnormal_model_loss, 'ro', label='loss')\n",
    "ax[4].set_xlabel('Epochs')\n",
    "ax[4].set_ylabel(' batchnormal loss')\n",
    "\n",
    "\n",
    "# 테스트셋에 모델 적용\n",
    "print(\"\\n ori Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
    "# 테스트셋에 모델 적용\n",
    "print(\"\\n dropout Test Accuracy: %.4f\" % (regularizers_model.evaluate(X_test, Y_test)[1]))\n",
    "# 테스트셋에 모델 적용\n",
    "print(\"\\n smaller Test Accuracy: %.4f\" % (smaller_model.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
