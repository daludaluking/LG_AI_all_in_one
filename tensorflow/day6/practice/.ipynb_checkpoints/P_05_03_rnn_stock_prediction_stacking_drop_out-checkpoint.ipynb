{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_length=2\n",
    "x_data_dim=4\n",
    "batch_size=100\n",
    "min_max_normalization_flag=True\n",
    "\n",
    "data_dir = '../dataset'\n",
    "fname = os.path.join(data_dir, 'data-02-stock_daily.csv')\n",
    "df = pd.read_csv(fname)\n",
    "dataset=df.copy()\n",
    "ori_Y=dataset.pop(\"Close\")\n",
    "ori_X=dataset.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(ori_X,ori_Y, test_size=0.2, shuffle=False)\n",
    "X_train, X_val, Y_train, Y_val= train_test_split(X_train,Y_train, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 데이터의 min , max, mean, std 값 구하기.\n",
    "dataset_stats = X_train.describe()\n",
    "dataset_stats = dataset_stats.transpose()\n",
    "\n",
    "## data normalization\n",
    "def min_max_norm(x):\n",
    "  return (x - dataset_stats['min']) / (dataset_stats['max'] - dataset_stats['min'])\n",
    "\n",
    "def standard_norm(x):\n",
    "  return (x - dataset_stats['mean']) / dataset_stats['std']\n",
    "\n",
    "if min_max_normalization_flag==True:\n",
    "    min_max_norm_train_data = min_max_norm(X_train)\n",
    "    min_max_norm_val_data = min_max_norm(X_val)\n",
    "    min_max_norm_test_data = min_max_norm(X_test)\n",
    "\n",
    "    data_gen_train=tf.keras.preprocessing.sequence.TimeseriesGenerator(min_max_norm_train_data.values.tolist(), Y_train.values.tolist(),\n",
    "                                                                        length=seq_length, sampling_rate=1,\n",
    "                                                                        batch_size=batch_size)\n",
    "    data_gen_val=tf.keras.preprocessing.sequence.TimeseriesGenerator(min_max_norm_val_data.values.tolist(), Y_val.values.tolist(),\n",
    "                                                                       length=seq_length, sampling_rate=1,\n",
    "                                                                       batch_size=batch_size)\n",
    "    data_gen_test=tf.keras.preprocessing.sequence.TimeseriesGenerator(min_max_norm_test_data.values.tolist(), Y_test.values.tolist(),\n",
    "                                                                       length=seq_length, sampling_rate=1,\n",
    "                                                                       batch_size=batch_size)\n",
    "else:\n",
    "    data_gen_train = tf.keras.preprocessing.sequence.TimeseriesGenerator(X_train.values.tolist(),Y_train.values.tolist(),\n",
    "                                                                   length=seq_length, sampling_rate=1,\n",
    "                                                                   batch_size=batch_size)\n",
    "    data_gen_val = tf.keras.preprocessing.sequence.TimeseriesGenerator(X_val.values.tolist(),Y_val.values.tolist(),\n",
    "                                                                   length=seq_length, sampling_rate=1,\n",
    "                                                                   batch_size=batch_size)\n",
    "    data_gen_test = tf.keras.preprocessing.sequence.TimeseriesGenerator(X_test.values.tolist(),Y_test.values.tolist(),\n",
    "                                                                        length=seq_length, sampling_rate=1,\n",
    "                                                                        batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 모델\n",
    "input_Layer = tf.keras.layers.Input(shape=(seq_length,x_data_dim))\n",
    "x= tf.keras.layers.SimpleRNN(20,dropout = 0.1, recurrent_dropout = 0.5, return_sequences=True,activation='tanh')(input_Layer)\n",
    "x= tf.keras.layers.SimpleRNN(10, dropout = 0.1, recurrent_dropout = 0.5,activation='tanh')(x)\n",
    "x=tf.keras.layers.Dense(100,activation='relu')(x)\n",
    "x=tf.keras.layers.Dense(50,activation='relu')(x)\n",
    "Out_Layer=tf.keras.layers.Dense(1,activation=None)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_Layer], outputs=[Out_Layer])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_function=tf.keras.losses.mean_squared_error\n",
    "optimize=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "metric=tf.keras.metrics.mean_absolute_error\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimize,\n",
    "              metrics=[metric])\n",
    "\n",
    "history = model.fit(\n",
    "      data_gen_train,\n",
    "      validation_data=data_gen_val,\n",
    "      steps_per_epoch=len(X_train)/batch_size,\n",
    "      epochs=500,\n",
    "      validation_freq=1\n",
    ")\n",
    "print(model.evaluate(data_gen_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_X, test_data_Y=data_gen_test[0]\n",
    "prediction_Y=model.predict(test_data_X).flatten()\n",
    "Y_test=test_data_Y.flatten()\n",
    "\n",
    "visual_y=[]\n",
    "visual_pre_y=[]\n",
    "for i in range(len(prediction_Y)):\n",
    "    label = Y_test[i]\n",
    "    prediction = prediction_Y[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))\n",
    "    visual_y.append(label)\n",
    "    visual_pre_y.append(prediction)\n",
    "\n",
    "time = range(1, len(visual_y) + 1)\n",
    "plt.plot(time, visual_y, 'r', label='ture')\n",
    "plt.plot(time, visual_pre_y, 'b', label='prediction')\n",
    "plt.title('stock prediction')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
