{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "## data 선언\n",
    "x_data = [[0.,0.], [0.,1.], [1.,0.],[1.,1.]]\n",
    "y_data = [[0.], [1.], [1.], [0.]]\n",
    "test_data=[[0.5, 0.5]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 43\n",
      "Trainable params: 43\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## tf.keras를 활용한 perceptron 모델 구현.\n",
    "# 실제 입력의 차원 ( None, 2) 여기서 None은 default값으로 정의 그러므로 뒤 입력 데이터의 차원만 정의를 해주시면 됩니다.\n",
    "## (2,) -> 1차원  [ x1, x2 ]\n",
    "## 가지고 있는 data 는 [[0.,0.], [0.,1.], [1.,0.],[1.,1.]] ->  1차원 인 (2,)의 데이터 4개 를 가지고 있는 상태\n",
    "### (batch_size(데이터의 갯수) , 들어올 데이터의 변수의 갯수 (입력 데이터 차원)) -> ( None, 입력 데이터의 차원 )\n",
    "## 만약 이미지 데이터를 넣는다면 ?\n",
    "### 이미지데이터는 (w, h, c)\n",
    "## ( None, w, ,h, c ) 그러므로 tf.keras.layers.Input(shape=(w,h,c))\n",
    "input_Layer = tf.keras.layers.Input(shape=(2,))\n",
    "x1 = tf.keras.layers.Dense(4, activation='sigmoid')(input_Layer)\n",
    "x2 = tf.keras.layers.Dense(5, activation='sigmoid')(x1)\n",
    "Out_Layer= tf.keras.layers.Dense(1, activation='sigmoid')(x2)\n",
    "model = tf.keras.Model(inputs=[input_Layer], outputs=[Out_Layer])\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 loss, 학습 방법 결정하기\n",
    "optimizer=tf.keras.optimizers.SGD(learning_rate=0.5) ### 경사 하강법으로 global min 에 찾아가는 최적화 방법 선언.\n",
    "loss=tf.keras.losses.binary_crossentropy  ## 예측값 과 정답의 오차값 정의.\n",
    "metrics=tf.keras.metrics.binary_accuracy ### 학습하면서 평가할 메트릭스 선언언\n",
    "\n",
    "# 모델 컴파일하기\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[metrics])\n",
    "\n",
    "# 모델 동작하기\n",
    "model.fit(x_data, y_data, epochs=2000, batch_size=4)\n",
    "# model.fit(x_data,y_data, epochs=1000,)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
